{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 1: AI-Generated System Design & Database Seeding\n",
    "\n",
    "**Objective:** Use the PRD artifact from Day 1 to generate a detailed SQL database schema, create realistic seed data, and then use those outputs to create and seed a live, local database file.\n",
    "\n",
    "**Estimated Time:** 150 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 2! Today, we transition from *what* we're building to *how* we'll build it. In this lab, you will act as the lead architect for the Onboarding Tool. Your task is to use the PRD to define the data structure of the application and create a tangible database artifact that will be used for the rest of the course.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the `day1_prd.md` artifact from Day 1. This document is the primary source of truth for our project and provides the necessary context for the LLM to make intelligent design suggestions.\n",
    "\n",
    "**Model Selection:**\n",
    "Feel free to experiment with different models by changing the `model_name` in `setup_llm_client()`. Models with strong reasoning capabilities, like `gpt-4o`, `o3`, or `gemini-2.5-pro`, are excellent choices for design tasks.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the PRD from the `artifacts` directory.\n",
    "- `save_artifact()`: To save the generated SQL schema and seed data.\n",
    "- `clean_llm_output()`: To remove markdown fences from the generated SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD from Day 1\n",
    "prd_content = load_artifact(\"artifacts/day1_prd.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load day1_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating the SQL Schema\n",
    "\n",
    "**Task:** Use the PRD to generate a normalized SQL schema for the application.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a Database Administrator (DBA).\n",
    "2.  Provide the `prd_content` as context.\n",
    "3.  Ask the LLM to design a normalized SQL schema with at least two tables (e.g., `users` and `onboarding_tasks`).\n",
    "4.  The output should be the raw `CREATE TABLE` statements.\n",
    "5.  Save the generated SQL to `artifacts/schema.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 12:24:03,368 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQL Schema ---\n",
      "CREATE TABLE companies (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    name VARCHAR(255) NOT NULL,\n",
      "    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
      ");\n",
      "\n",
      "CREATE TABLE users (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    company_id UUID NOT NULL REFERENCES companies(id) ON DELETE RESTRICT,\n",
      "    full_name VARCHAR(255) NOT NULL,\n",
      "    email VARCHAR(255) NOT NULL,\n",
      "    password_hash TEXT NOT NULL,\n",
      "    role VARCHAR(50) NOT NULL CHECK (role IN ('hr_admin', 'hiring_manager', 'new_hire')),\n",
      "    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    UNIQUE (company_id, email)\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_plan_templates (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    company_id UUID NOT NULL REFERENCES companies(id) ON DELETE CASCADE,\n",
      "    name VARCHAR(255) NOT NULL,\n",
      "    description TEXT,\n",
      "    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    UNIQUE (company_id, name)\n",
      ");\n",
      "\n",
      "CREATE TABLE template_tasks (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    template_id UUID NOT NULL REFERENCES onboarding_plan_templates(id) ON DELETE CASCADE,\n",
      "    title VARCHAR(255) NOT NULL,\n",
      "    description TEXT,\n",
      "    default_assignee_type VARCHAR(50) NOT NULL CHECK (default_assignee_type IN ('new_hire', 'hiring_manager')),\n",
      "    due_days_after_start INTEGER NOT NULL CHECK (due_days_after_start >= 0),\n",
      "    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_journeys (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    company_id UUID NOT NULL REFERENCES companies(id) ON DELETE CASCADE,\n",
      "    new_hire_user_id UUID NOT NULL REFERENCES users(id) ON DELETE RESTRICT,\n",
      "    hiring_manager_user_id UUID NOT NULL REFERENCES users(id) ON DELETE RESTRICT,\n",
      "    template_id UUID NOT NULL REFERENCES onboarding_plan_templates(id) ON DELETE RESTRICT,\n",
      "    start_date DATE NOT NULL,\n",
      "    status VARCHAR(50) NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'completed', 'cancelled')),\n",
      "    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    CHECK (new_hire_user_id <> hiring_manager_user_id)\n",
      ");\n",
      "\n",
      "CREATE TABLE journey_tasks (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    journey_id UUID NOT NULL REFERENCES onboarding_journeys(id) ON DELETE CASCADE,\n",
      "    template_task_id UUID NOT NULL REFERENCES template_tasks(id) ON DELETE RESTRICT,\n",
      "    assignee_user_id UUID NOT NULL REFERENCES users(id) ON DELETE RESTRICT,\n",
      "    title VARCHAR(255) NOT NULL,\n",
      "    description TEXT,\n",
      "    due_date DATE NOT NULL,\n",
      "    status VARCHAR(50) NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'in_progress', 'completed')),\n",
      "    completed_at TIMESTAMPTZ,\n",
      "    completed_by_user_id UUID REFERENCES users(id) ON DELETE SET NULL,\n",
      "    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
      "    CHECK ((status = 'completed' AND completed_at IS NOT NULL AND completed_by_user_id IS NOT NULL) OR (status <> 'completed' AND completed_at IS NULL AND completed_by_user_id IS NULL))\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate the SQL schema from the PRD.\n",
    "schema_prompt = f\"\"\"\n",
    "You are a database administrator and SQL expert. Based on the following Product Requirements Document (PRD), generate a complete SQL schema for a relational database. Ensure that the schema includes tables, columns with appropriate data types, primary keys, foreign keys, and any necessary constraints.\n",
    "PRD:\n",
    "{prd_content}\n",
    "The output should be the raw CREATE TABLE statements without any additional explanations or comments.\n",
    "\"\"\"\n",
    "enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(enhanced_schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'artifacts/schema.sql')\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating schema with gemini-2.5-pro ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 15:17:31,987 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n",
      "2025-10-28 15:17:32,737 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n",
      "2025-10-28 15:19:23,890 ag_aisoftdev.utils ERROR Model 'gpt-4' is not in the list of recommended models. provider=None model=gpt-4 latency_ms=None artifacts_path=None\n",
      "2025-10-28 15:19:23,900 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating schema with gemini-2.5-pro: [google:gemini-2.5-pro] completion error: Server disconnected without sending a response.\n",
      "\n",
      "=== Generating schema with gpt-4 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 15:19:41,811 ag_aisoftdev.utils ERROR Model 'claude-3' is not in the list of recommended models. provider=None model=claude-3 latency_ms=None artifacts_path=None\n",
      "2025-10-28 15:19:41,822 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating schema with gpt-4: [None:None] completion error: API client not initialized.\n",
      "\n",
      "=== Generating schema with claude-3 ===\n",
      "\n",
      "Error generating schema with claude-3: [None:None] completion error: API client not initialized.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, prompt_enhancer\n",
    "\n",
    "def generate_schema_with_model(prd_content, model_name):\n",
    "    \"\"\"Generate SQL schema using specified model\"\"\"\n",
    "    client, model, provider = setup_llm_client(model_name=model_name)\n",
    "    \n",
    "    schema_prompt = f\"\"\"\n",
    "    You are a database administrator and SQL expert. Based on the following Product Requirements Document (PRD), \n",
    "    generate a complete SQL schema for a relational database. The schema must include:\n",
    "    1. All necessary tables for an onboarding system\n",
    "    2. Appropriate columns with specific data types\n",
    "    3. Primary and foreign key relationships\n",
    "    4. Relevant constraints and indices\n",
    "    5. Timestamp fields for audit purposes\n",
    "\n",
    "    PRD:\n",
    "    {prd_content}\n",
    "\n",
    "    Provide only the raw CREATE TABLE statements without explanations.\n",
    "    \"\"\"\n",
    "    \n",
    "    enhanced_prompt = prompt_enhancer(schema_prompt)\n",
    "    generated_schema = get_completion(enhanced_prompt, client, model, provider)\n",
    "    return clean_llm_output(generated_schema, language='sql')\n",
    "\n",
    "def compare_schemas():\n",
    "    # Load the PRD\n",
    "    prd_content = load_artifact(\"artifacts/day1_prd.md\")\n",
    "    if not prd_content:\n",
    "        print(\"Error: Could not load PRD content\")\n",
    "        return\n",
    "\n",
    "    # Models to compare\n",
    "    models = [\n",
    "        \"gemini-2.5-pro\",  # Google's model\n",
    "        \"claude-sonnet-4-20250514\",     # Anthropic's model\n",
    "        \"gpt-5-2025-08-07\",              # OpenAI's model\n",
    "    ]\n",
    "\n",
    "    # Generate schemas with each model\n",
    "    for model in models:\n",
    "        print(f\"\\n=== Generating schema with {model} ===\\n\")\n",
    "        try:\n",
    "            schema = generate_schema_with_model(prd_content, model)\n",
    "            \n",
    "            # Save to model-specific files\n",
    "            filename = f\"artifacts/schema_{model.replace('-', '_')}.sql\"\n",
    "            save_artifact(schema, filename)\n",
    "            \n",
    "            print(f\"Schema generated with {model}:\")\n",
    "            print(schema)\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating schema with {model}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    compare_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Realistic Seed Data\n",
    "\n",
    "**Task:** Prompt the LLM to generate realistic seed data that conforms to the schema you just created.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide both the `prd_content` and the `cleaned_schema` as context.\n",
    "3.  Instruct the LLM to generate 5-10 realistic `INSERT` statements for your tables.\n",
    "4.  The data should be relevant to a new hire onboarding tool (e.g., sample user names and task titles like \"Complete HR Paperwork\").\n",
    "5.  Save the generated `INSERT` statements to `artifacts/seed_data.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n",
      "INSERT INTO companies (id, name) VALUES ('4d3b8f2d-8b1e-4a6c-9e2a-1b9d7f3c5e8a', 'Innovate Solutions Inc.');\n",
      "INSERT INTO users (id, company_id, full_name, email, password_hash, role) VALUES ('a8b9c0d1-e2f3-4a5b-8c9d-0e1f2a3b4c5d', '4d3b8f2d-8b1e-4a6c-9e2a-1b9d7f3c5e8a', 'Hannah Reed', 'h.reed@innovatesolutions.com', '$2b$12$D8c.Q3.y9yZ8Q.c8N.f9uOF0Z.eJ5lZ3K.z6B.wX9tC.gH4iJ2j5O', 'hr_admin');\n",
      "INSERT INTO users (id, company_id, full_name, email, password_hash, role) VALUES ('b1c2d3e4-f5a6-7b8c-9d0e-1f2a3b4c5d6e', '4d3b8f2d-8b1e-4a6c-9e2a-1b9d7f3c5e8a', 'Sarah Jones', 's.jones@innovatesolutions.com', '$2b$12$E9f.R4.z0aX7Q.d9O.g0vPG1Z.fK6mZ4L.a7C.xY0uD.hI5jK3k6P', 'hiring_manager');\n",
      "INSERT INTO users (id, company_id, full_name, email, password_hash, role) VALUES ('c4d5e6f7-a8b9-0c1d-2e3f-4a5b6c7d8e9f', '4d3b8f2d-8b1e-4a6c-9e2a-1b9d7f3c5e8a', 'Priya Patel', 'p.patel@innovatesolutions.com', '$2b$12$F0g.S5.a1bY8R.e0P.h1wQH2A.gL7nZ5M.b8D.yZ1vE.iJ6lL4l7Q', 'new_hire');\n",
      "INSERT INTO onboarding_plan_templates (id, company_id, name, description) VALUES ('d7e8f9a0-b1c2-3d4e-5f6a-7b8c9d0e1f2a', '4d3b8f2d-8b1e-4a6c-9e2a-1b9d7f3c5e8a', 'Software Engineer Onboarding', 'A comprehensive onboarding plan for new software engineers, covering technical setup, team integration, and first-project contributions.');\n",
      "INSERT INTO template_tasks (id, template_id, title, description, default_assignee_type, due_days_after_start) VALUES ('e1f2a3b4-c5d6-7e8f-9a0b-1c2d3e4f5a6b', 'd7e8f9a0-b1c2-3d4e-5f6a-7b8c9d0e1f2a', 'Set up local development environment', 'Follow the engineering wiki to install all necessary software, clone the main repository, and run the local test suite.', 'new_hire', 1);\n",
      "INSERT INTO template_tasks (id, template_id, title, description, default_assignee_type, due_days_after_start) VALUES ('f3a4b5c6-d7e8-9f0a-1b2c-3d4e5f6a7b8c', 'd7e8f9a0-b1c2-3d4e-5f6a-7b8c9d0e1f2a', 'Schedule 30-day check-in', 'Book a 30-minute meeting with the new hire to discuss their progress, answer questions, and set goals for the next 60 days.', 'hiring_manager', 5);\n",
      "INSERT INTO onboarding_journeys (id, company_id, new_hire_user_id, hiring_manager_user_id, template_id, start_date) VALUES ('a0b1c2d3-e4f5-6a7b-8c9d-0e1f2a3b4c5d', '4d3b8f2d-8b1e-4a6c-9e2a-1b9d7f3c5e8a', 'c4d5e6f7-a8b9-0c1d-2e3f-4a5b6c7d8e9f', 'b1c2d3e4-f5a6-7b8c-9d0e-1f2a3b4c5d6e', 'd7e8f9a0-b1c2-3d4e-5f6a-7b8c9d0e1f2a', CURRENT_DATE);\n",
      "INSERT INTO journey_tasks (id, journey_id, template_task_id, assignee_user_id, title, description, due_date) VALUES ('b3c4d5e6-f7a8-9b0c-1d2e-3f4a5b6c7d8e', 'a0b1c2d3-e4f5-6a7b-8c9d-0e1f2a3b4c5d', 'e1f2a3b4-c5d6-7e8f-9a0b-1c2d3e4f5a6b', 'c4d5e6f7-a8b9-0c1d-2e3f-4a5b6c7d8e9f', 'Set up local development environment', 'Follow the engineering wiki to install all necessary software, clone the main repository, and run the local test suite.', CURRENT_DATE + INTERVAL '1 day');\n",
      "INSERT INTO journey_tasks (id, journey_id, template_task_id, assignee_user_id, title, description, due_date) VALUES ('c6d7e8f9-a0b1-2c3d-4e5f-6a7b8c9d0e1f', 'a0b1c2d3-e4f5-6a7b-8c9d-0e1f2a3b4c5d', 'f3a4b5c6-d7e8-9f0a-1b2c-3d4e5f6a7b8c', 'b1c2d3e4-f5a6-7b8c-9d0e-1f2a3b4c5d6e', 'Schedule 30-day check-in', 'Book a 30-minute meeting with the new hire to discuss their progress, answer questions, and set goals for the next 60 days.', CURRENT_DATE + INTERVAL '5 days');\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate realistic seed data.\n",
    "seed_data_prompt = f\"\"\"\n",
    "Using the following SQL schema, and Product Requirements Document, generate realistic SQL INSERT statements to seed the database with sample data. Ensure that the data respects all constraints defined in the schema, including primary keys, foreign keys, and data types.\n",
    "SQL Schema:\n",
    "{cleaned_schema}\n",
    "Product Requirements Document (PRD):\n",
    "{prd_content}\n",
    "The output should be a series of 10 SQL INSERT statements without any additional explanations or comments.\n",
    "The data should be relevant to the new hire onboarding tool application context described in the PRD.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql')\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Creating and Seeding a Live Database\n",
    "\n",
    "**Task:** This is a critical technical step. You will write a Python script to execute the generated SQL files, creating a live `onboarding.db` file that your application will use.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Complete the `create_database` function below.\n",
    "2.  The function should first connect to (and thus create) a SQLite database file named `artifacts/onboarding.db`.\n",
    "3.  It should then open and execute the `schema.sql` file to create the tables.\n",
    "4.  Finally, it should open and execute the `seed_data.sql` file to populate the tables.\n",
    "5.  Use a `try...finally` block to ensure the database connection is always closed, even if an error occurs.\n",
    "\n",
    "> **Hint:** The `try...finally` block is a crucial Python pattern. The code in the `finally` block will run whether the `try` block succeeds or fails, making it the perfect place to ensure resources like database connections are always closed.\n",
    "\n",
    "**Expected Quality:** A physical `onboarding.db` file in your `artifacts` folder. This is a tangible asset that proves your design is valid and provides a concrete foundation for backend development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # TODO: Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # TODO: Read the content of the schema file using load_artifact.\n",
    "        schema_sql = \"\"\n",
    "        \n",
    "        # TODO: Execute the schema SQL script.\n",
    "        # Hint: Use cursor.executescript() for multi-statement SQL strings.\n",
    "        \n",
    "        print(\"Tables created successfully.\")\n",
    "\n",
    "        # TODO: Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            # Load and execute the seed data\n",
    "            pass # Your code here\n",
    "\n",
    "        # TODO: Commit the changes to the database.\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        # TODO: Ensure the connection is closed if it was opened.\n",
    "        pass # Your code here\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"artifacts\", \"onboarding.db\")\n",
    "schema_file = os.path.join(project_root, \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now moved from abstract requirements to a concrete, physical database artifact. You've used an LLM to design a schema, generate realistic test data, and then used a Python script to bring that database to life. This `onboarding.db` file is the foundation upon which we will build our API in Day 3.\n",
    "\n",
    "> **Key Takeaway:** The ability to generate structured data definitions (like a SQL schema) from unstructured text (like a PRD) is a core skill in AI-assisted development. It automates a critical and often time-consuming design step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
