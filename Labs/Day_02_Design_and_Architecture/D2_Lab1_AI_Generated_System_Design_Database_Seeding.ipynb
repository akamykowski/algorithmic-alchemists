{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 1: AI-Generated System Design & Database Seeding\n",
    "\n",
    "**Objective:** Use the PRD artifact from Day 1 to generate a detailed SQL database schema, create realistic seed data, and then use those outputs to create and seed a live, local database file.\n",
    "\n",
    "**Estimated Time:** 150 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 2! Today, we transition from *what* we're building to *how* we'll build it. In this lab, you will act as the lead architect for the Onboarding Tool. Your task is to use the PRD to define the data structure of the application and create a tangible database artifact that will be used for the rest of the course.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the `day1_prd.md` artifact from Day 1. This document is the primary source of truth for our project and provides the necessary context for the LLM to make intelligent design suggestions.\n",
    "\n",
    "**Model Selection:**\n",
    "Feel free to experiment with different models by changing the `model_name` in `setup_llm_client()`. Models with strong reasoning capabilities, like `gpt-4o`, `o3`, or `gemini-2.5-pro`, are excellent choices for design tasks.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the PRD from the `artifacts` directory.\n",
    "- `save_artifact()`: To save the generated SQL schema and seed data.\n",
    "- `clean_llm_output()`: To remove markdown fences from the generated SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:52:01,288 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD from Day 1\n",
    "prd_content = load_artifact(\"artifacts/day1_prd.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load day1_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating the SQL Schema\n",
    "\n",
    "**Task:** Use the PRD to generate a normalized SQL schema for the application.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a Database Administrator (DBA).\n",
    "2.  Provide the `prd_content` as context.\n",
    "3.  Ask the LLM to design a normalized SQL schema with at least two tables (e.g., `users` and `onboarding_tasks`).\n",
    "4.  The output should be the raw `CREATE TABLE` statements.\n",
    "5.  Save the generated SQL to `artifacts/schema.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:52:01,854 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SQL Enhanced Schema Generation Prompt ---\n",
      "<persona>\n",
      "You are a Senior Database Architect and SQL expert.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "Below is the complete Product Requirements Document (PRD) for “OnboardPro,” an employee-onboarding platform. Use it as the single source of truth for understanding the data domain, entities, and relationships.\n",
      "\n",
      "[START_PRD]\n",
      "# Product Requirements Document: OnboardPro\n",
      "| Status | Draft |\n",
      "| Author | Product Team – Onboarding |\n",
      "| Version | 1.0 |\n",
      "| Last Updated | 2023-10-27 |\n",
      "…(full PRD exactly as provided by the user, unchanged)…\n",
      "[END_PRD]\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "1. Think step by step to identify all entities, their attributes, and relationships needed to satisfy every functional and non-functional requirement in the PRD. Perform this reasoning silently and do NOT reveal it in the final answer.\n",
      "\n",
      "2. Generate a complete, syntactically correct SQLite schema that:\n",
      "   • Creates every necessary table with appropriate column names and data types.  \n",
      "   • Defines primary keys, foreign keys, UNIQUE constraints, and NOT NULL constraints where appropriate.  \n",
      "   • Includes junction tables for any many-to-many relationships.  \n",
      "   • Implements basic audit fields (created_at, updated_at) for all main tables.  \n",
      "   • Provides ON DELETE CASCADE or other relevant referential actions where sensible.  \n",
      "   • Drops a table if it already exists before recreating it.\n",
      "\n",
      "3. Adhere strictly to the required output format described below. Do not include explanations, comments, or any text other than the SQL statements.\n",
      "\n",
      "4. Ensure the final SQL executes without modification in a standard SQLite environment (e.g., sqlite3 CLI).\n",
      "\n",
      "</instructions>\n",
      "\n",
      "<output_format>\n",
      "Your entire response must be raw SQL only, following this template style:\n",
      "\n",
      "DROP TABLE IF EXISTS table_name;\n",
      "\n",
      "CREATE TABLE table_name (\n",
      "    column_name1 data_type constraint,\n",
      "    column_name2 data_type constraint,\n",
      "    ...\n",
      ");\n",
      "\n",
      "-- Repeat DROP + CREATE for each table in the correct dependency order.\n",
      "</output_format>\n",
      "--- Generating SQL Schema ---\n",
      "DROP TABLE IF EXISTS notifications;\n",
      "DROP TABLE IF EXISTS assigned_tasks;\n",
      "DROP TABLE IF EXISTS onboarding_processes;\n",
      "DROP TABLE IF EXISTS tasks;\n",
      "DROP TABLE IF EXISTS onboarding_plans;\n",
      "DROP TABLE IF EXISTS documents;\n",
      "DROP TABLE IF EXISTS users;\n",
      "DROP TABLE IF EXISTS companies;\n",
      "\n",
      "CREATE TABLE companies (\n",
      "    company_id INTEGER PRIMARY KEY,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP\n",
      ");\n",
      "\n",
      "CREATE TABLE users (\n",
      "    user_id INTEGER PRIMARY KEY,\n",
      "    company_id INTEGER NOT NULL,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    password_hash TEXT NOT NULL,\n",
      "    first_name TEXT NOT NULL,\n",
      "    last_name TEXT NOT NULL,\n",
      "    role TEXT NOT NULL CHECK(role IN ('Admin', 'Hiring Manager', 'New Hire')),\n",
      "    manager_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (company_id) REFERENCES companies(company_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (manager_id) REFERENCES users(user_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE documents (\n",
      "    document_id INTEGER PRIMARY KEY,\n",
      "    company_id INTEGER NOT NULL,\n",
      "    file_name TEXT NOT NULL,\n",
      "    file_path TEXT NOT NULL UNIQUE,\n",
      "    file_type TEXT,\n",
      "    uploaded_by_user_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (company_id) REFERENCES companies(company_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (uploaded_by_user_id) REFERENCES users(user_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_plans (\n",
      "    plan_id INTEGER PRIMARY KEY,\n",
      "    company_id INTEGER NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    created_by_user_id INTEGER,\n",
      "    is_active INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    UNIQUE (company_id, title),\n",
      "    FOREIGN KEY (company_id) REFERENCES companies(company_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (created_by_user_id) REFERENCES users(user_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE tasks (\n",
      "    task_id INTEGER PRIMARY KEY,\n",
      "    plan_id INTEGER NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    due_days_after_start INTEGER NOT NULL,\n",
      "    order_in_plan INTEGER NOT NULL,\n",
      "    document_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (plan_id) REFERENCES onboarding_plans(plan_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (document_id) REFERENCES documents(document_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_processes (\n",
      "    process_id INTEGER PRIMARY KEY,\n",
      "    new_hire_user_id INTEGER NOT NULL UNIQUE,\n",
      "    plan_id INTEGER NOT NULL,\n",
      "    hiring_manager_user_id INTEGER NOT NULL,\n",
      "    start_date TEXT NOT NULL,\n",
      "    status TEXT NOT NULL DEFAULT 'Not Started' CHECK(status IN ('Not Started', 'In Progress', 'Completed')),\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (new_hire_user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (plan_id) REFERENCES onboarding_plans(plan_id) ON DELETE RESTRICT,\n",
      "    FOREIGN KEY (hiring_manager_user_id) REFERENCES users(user_id) ON DELETE RESTRICT\n",
      ");\n",
      "\n",
      "CREATE TABLE assigned_tasks (\n",
      "    assigned_task_id INTEGER PRIMARY KEY,\n",
      "    process_id INTEGER NOT NULL,\n",
      "    task_id INTEGER NOT NULL,\n",
      "    status TEXT NOT NULL DEFAULT 'Pending' CHECK(status IN ('Pending', 'Completed')),\n",
      "    due_date TEXT NOT NULL,\n",
      "    completed_at TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    UNIQUE (process_id, task_id),\n",
      "    FOREIGN KEY (process_id) REFERENCES onboarding_processes(process_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_id) REFERENCES tasks(task_id) ON DELETE RESTRICT\n",
      ");\n",
      "\n",
      "CREATE TABLE notifications (\n",
      "    notification_id INTEGER PRIMARY KEY,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    event_type TEXT NOT NULL,\n",
      "    content TEXT NOT NULL,\n",
      "    is_read INTEGER NOT NULL DEFAULT 0,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE\n",
      ");\n",
      "DROP TABLE IF EXISTS notifications;\n",
      "DROP TABLE IF EXISTS assigned_tasks;\n",
      "DROP TABLE IF EXISTS onboarding_processes;\n",
      "DROP TABLE IF EXISTS tasks;\n",
      "DROP TABLE IF EXISTS onboarding_plans;\n",
      "DROP TABLE IF EXISTS documents;\n",
      "DROP TABLE IF EXISTS users;\n",
      "DROP TABLE IF EXISTS companies;\n",
      "\n",
      "CREATE TABLE companies (\n",
      "    company_id INTEGER PRIMARY KEY,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP\n",
      ");\n",
      "\n",
      "CREATE TABLE users (\n",
      "    user_id INTEGER PRIMARY KEY,\n",
      "    company_id INTEGER NOT NULL,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    password_hash TEXT NOT NULL,\n",
      "    first_name TEXT NOT NULL,\n",
      "    last_name TEXT NOT NULL,\n",
      "    role TEXT NOT NULL CHECK(role IN ('Admin', 'Hiring Manager', 'New Hire')),\n",
      "    manager_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (company_id) REFERENCES companies(company_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (manager_id) REFERENCES users(user_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE documents (\n",
      "    document_id INTEGER PRIMARY KEY,\n",
      "    company_id INTEGER NOT NULL,\n",
      "    file_name TEXT NOT NULL,\n",
      "    file_path TEXT NOT NULL UNIQUE,\n",
      "    file_type TEXT,\n",
      "    uploaded_by_user_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (company_id) REFERENCES companies(company_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (uploaded_by_user_id) REFERENCES users(user_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_plans (\n",
      "    plan_id INTEGER PRIMARY KEY,\n",
      "    company_id INTEGER NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    created_by_user_id INTEGER,\n",
      "    is_active INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    UNIQUE (company_id, title),\n",
      "    FOREIGN KEY (company_id) REFERENCES companies(company_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (created_by_user_id) REFERENCES users(user_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE tasks (\n",
      "    task_id INTEGER PRIMARY KEY,\n",
      "    plan_id INTEGER NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    due_days_after_start INTEGER NOT NULL,\n",
      "    order_in_plan INTEGER NOT NULL,\n",
      "    document_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (plan_id) REFERENCES onboarding_plans(plan_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (document_id) REFERENCES documents(document_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_processes (\n",
      "    process_id INTEGER PRIMARY KEY,\n",
      "    new_hire_user_id INTEGER NOT NULL UNIQUE,\n",
      "    plan_id INTEGER NOT NULL,\n",
      "    hiring_manager_user_id INTEGER NOT NULL,\n",
      "    start_date TEXT NOT NULL,\n",
      "    status TEXT NOT NULL DEFAULT 'Not Started' CHECK(status IN ('Not Started', 'In Progress', 'Completed')),\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (new_hire_user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (plan_id) REFERENCES onboarding_plans(plan_id) ON DELETE RESTRICT,\n",
      "    FOREIGN KEY (hiring_manager_user_id) REFERENCES users(user_id) ON DELETE RESTRICT\n",
      ");\n",
      "\n",
      "CREATE TABLE assigned_tasks (\n",
      "    assigned_task_id INTEGER PRIMARY KEY,\n",
      "    process_id INTEGER NOT NULL,\n",
      "    task_id INTEGER NOT NULL,\n",
      "    status TEXT NOT NULL DEFAULT 'Pending' CHECK(status IN ('Pending', 'Completed')),\n",
      "    due_date TEXT NOT NULL,\n",
      "    completed_at TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    UNIQUE (process_id, task_id),\n",
      "    FOREIGN KEY (process_id) REFERENCES onboarding_processes(process_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_id) REFERENCES tasks(task_id) ON DELETE RESTRICT\n",
      ");\n",
      "\n",
      "CREATE TABLE notifications (\n",
      "    notification_id INTEGER PRIMARY KEY,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    event_type TEXT NOT NULL,\n",
      "    content TEXT NOT NULL,\n",
      "    is_read INTEGER NOT NULL DEFAULT 0,\n",
      "    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate the SQL schema from the PRD.\n",
    "schema_prompt = f\"\"\"\n",
    "You are a database administrator and SQL expert. Based on the following Product Requirements Document (PRD), generate a complete SQL schema for a relational database. Ensure that the schema includes tables, columns with appropriate data types, primary keys, foreign keys, and any necessary constraints.\n",
    "PRD:\n",
    "{prd_content}\n",
    "The output should be the raw CREATE TABLE statements without any additional explanations or comments.\n",
    "Ensure the schema is simple yet comprehensive enough to cover all aspects mentioned in the PRD.\n",
    "Ensure the schema is syntactically correct for SQLite.\n",
    "Drop any tables if they already exist before creating them.\n",
    "Ensure proper relationships between tables using foreign keys.\n",
    "\"\"\"\n",
    "enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "print(\"--- SQL Enhanced Schema Generation Prompt ---\")\n",
    "print(enhanced_schema_prompt)\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(\n",
    "        enhanced_schema_prompt,\n",
    "        client,\n",
    "        model_name,\n",
    "        api_provider,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'artifacts/schema.sql', overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Realistic Seed Data\n",
    "\n",
    "**Task:** Prompt the LLM to generate realistic seed data that conforms to the schema you just created.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide both the `prd_content` and the `cleaned_schema` as context.\n",
    "3.  Instruct the LLM to generate 5-10 realistic `INSERT` statements for your tables.\n",
    "4.  The data should be relevant to a new hire onboarding tool (e.g., sample user names and task titles like \"Complete HR Paperwork\").\n",
    "5.  Save the generated `INSERT` statements to `artifacts/seed_data.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:52:57,748 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SQL Enhanced Seed Data Generation Prompt ---\n",
      "<persona>\n",
      "You are a senior SQL database architect and HR-tech domain expert who routinely seeds relational databases with realistic, constraint-compliant sample data.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "You are preparing seed data for a fresh installation of the OnboardPro platform.  \n",
      "The full SQL schema (already executed) contains these tables and constraints:\n",
      "\n",
      "• companies(company_id PK, name UNIQUE NOT NULL, created_at, updated_at)  \n",
      "• users(user_id PK, company_id FK, email UNIQUE, password_hash, first_name, last_name, role CHECK('Admin','Hiring Manager','New Hire'), manager_id FK users.user_id, timestamps)  \n",
      "• documents(document_id PK, company_id FK, file_name, file_path UNIQUE, file_type, uploaded_by_user_id FK, timestamps)  \n",
      "• onboarding_plans(plan_id PK, company_id FK, title UNIQUE per company, description, created_by_user_id FK, is_active, timestamps)  \n",
      "• tasks(task_id PK, plan_id FK, title, description, due_days_after_start, order_in_plan, document_id FK, timestamps)  \n",
      "• onboarding_processes(process_id PK, new_hire_user_id UNIQUE FK, plan_id FK, hiring_manager_user_id FK, start_date, status CHECK('Not Started','In Progress','Completed'), timestamps)  \n",
      "• assigned_tasks(assigned_task_id PK, process_id FK, task_id FK, status CHECK('Pending','Completed'), due_date, completed_at, timestamps, UNIQUE(process_id, task_id))  \n",
      "• notifications(notification_id PK, user_id FK, event_type, content, is_read, created_at)\n",
      "\n",
      "NOT NULL columns and CHECK/UNIQUE constraints must be satisfied.  \n",
      "Use ISO-8601 timestamps (e.g., 2024-04-27T15:30:00Z) or CURRENT_TIMESTAMP.  \n",
      "Parent records must exist before child records.  \n",
      "Keep IDs internally consistent across all statements.  \n",
      "The seed data should reflect a realistic onboarding scenario for one company (“Acme Corp”) with:\n",
      "– 1 Admin (HR), 1 Hiring Manager, 1 New Hire  \n",
      "– 1 onboarding plan with 3 tasks (one linked to a document)  \n",
      "– 1 onboarding process derived from that plan  \n",
      "– Assigned tasks generated for each task in the plan  \n",
      "– At least 2 notifications (e.g., task assignment, reminder)\n",
      "\n",
      "Only reference the columns present in the schema.\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "1. Think step-by-step to ensure every foreign key and constraint is satisfied, but DO NOT reveal your reasoning.  \n",
      "2. Generate 10-15 SQL INSERT statements that insert all required rows for the scenario described in <context>.  \n",
      "3. Provide the statements in an order that respects foreign-key dependencies (companies → users → documents → onboarding_plans → tasks → onboarding_processes → assigned_tasks → notifications).  \n",
      "4. Use plausible, human-readable values (emails, file names, etc.).  \n",
      "5. Output only the SQL INSERT statements, one per line, with no comments, no code fences, and no additional text.\n",
      "</instructions>\n",
      "\n",
      "<examples>\n",
      "-- Example format only (do not reuse IDs):\n",
      "INSERT INTO companies (company_id,name) VALUES (1,'Example Inc');\n",
      "INSERT INTO users (user_id,company_id,email,password_hash,first_name,last_name,role) VALUES (1,1,'hr@example.com','hash','Ava','Stone','Admin');\n",
      "</examples>\n",
      "\n",
      "<output_format>\n",
      "Plain text list of 10-15 INSERT statements as per <instructions>.\n",
      "</output_format>\n",
      "--- Generating Seed Data ---\n",
      "INSERT INTO companies (company_id, name, created_at, updated_at) VALUES (1, 'Acme Corp', '2024-05-01T09:00:00Z', '2024-05-01T09:00:00Z');\n",
      "INSERT INTO users (user_id, company_id, email, password_hash, first_name, last_name, role, manager_id) VALUES (1, 1, 'alice.hr@acmecorp.com', 'pbkdf2:sha256:260000$abc$123', 'Alice', 'Anderson', 'Admin', NULL);\n",
      "INSERT INTO users (user_id, company_id, email, password_hash, first_name, last_name, role, manager_id) VALUES (2, 1, 'bob.manager@acmecorp.com', 'pbkdf2:sha256:260000$def$456', 'Bob', 'Brown', 'Hiring Manager', 1);\n",
      "INSERT INTO users (user_id, company_id, email, password_hash, first_name, last_name, role, manager_id) VALUES (3, 1, 'charlie.new@acmecorp.com', 'pbkdf2:sha256:260000$ghi$789', 'Charlie', 'Chen', 'New Hire', 2);\n",
      "INSERT INTO documents (document_id, company_id, file_name, file_path, file_type, uploaded_by_user_id) VALUES (1, 1, 'Acme Corp Employee Handbook.pdf', '/docs/acme/handbook_v3.pdf', 'PDF', 1);\n",
      "INSERT INTO onboarding_plans (plan_id, company_id, title, description, created_by_user_id, is_active) VALUES (1, 1, 'Standard Engineering Onboarding', 'The standard onboarding plan for all new software engineers.', 1, TRUE);\n",
      "INSERT INTO tasks (task_id, plan_id, title, description, due_days_after_start, order_in_plan, document_id) VALUES (1, 1, 'Review Employee Handbook', 'Read and acknowledge the company policies outlined in the employee handbook.', 1, 1, 1);\n",
      "INSERT INTO tasks (task_id, plan_id, title, description, due_days_after_start, order_in_plan) VALUES (2, 1, 'Set up development environment', 'Follow the guide to install all necessary software and tools on your machine.', 3, 2);\n",
      "INSERT INTO tasks (task_id, plan_id, title, description, due_days_after_start, order_in_plan) VALUES (3, 1, 'First 1:1 with Manager', 'Schedule and complete your introductory one-on-one meeting with your manager.', 5, 3);\n",
      "INSERT INTO onboarding_processes (process_id, new_hire_user_id, plan_id, hiring_manager_user_id, start_date, status) VALUES (1, 3, 1, 2, '2024-05-15', 'In Progress');\n",
      "INSERT INTO assigned_tasks (assigned_task_id, process_id, task_id, status, due_date) VALUES (1, 1, 1, 'Pending', '2024-05-16');\n",
      "INSERT INTO assigned_tasks (assigned_task_id, process_id, task_id, status, due_date) VALUES (2, 1, 2, 'Pending', '2024-05-18');\n",
      "INSERT INTO assigned_tasks (assigned_task_id, process_id, task_id, status, due_date) VALUES (3, 1, 3, 'Pending', '2024-05-20');\n",
      "INSERT INTO notifications (notification_id, user_id, event_type, content, is_read, created_at) VALUES (1, 3, 'ONBOARDING_STARTED', 'Welcome to Acme Corp, Charlie! Your onboarding tasks have been assigned.', FALSE, '2024-05-15T09:05:00Z');\n",
      "INSERT INTO notifications (notification_id, user_id, event_type, content, is_read, created_at) VALUES (2, 3, 'TASK_DUE_SOON', 'Reminder: Your task \"Review Employee Handbook\" is due tomorrow.', FALSE, '2024-05-15T14:00:00Z');\n",
      "INSERT INTO companies (company_id, name, created_at, updated_at) VALUES (1, 'Acme Corp', '2024-05-01T09:00:00Z', '2024-05-01T09:00:00Z');\n",
      "INSERT INTO users (user_id, company_id, email, password_hash, first_name, last_name, role, manager_id) VALUES (1, 1, 'alice.hr@acmecorp.com', 'pbkdf2:sha256:260000$abc$123', 'Alice', 'Anderson', 'Admin', NULL);\n",
      "INSERT INTO users (user_id, company_id, email, password_hash, first_name, last_name, role, manager_id) VALUES (2, 1, 'bob.manager@acmecorp.com', 'pbkdf2:sha256:260000$def$456', 'Bob', 'Brown', 'Hiring Manager', 1);\n",
      "INSERT INTO users (user_id, company_id, email, password_hash, first_name, last_name, role, manager_id) VALUES (3, 1, 'charlie.new@acmecorp.com', 'pbkdf2:sha256:260000$ghi$789', 'Charlie', 'Chen', 'New Hire', 2);\n",
      "INSERT INTO documents (document_id, company_id, file_name, file_path, file_type, uploaded_by_user_id) VALUES (1, 1, 'Acme Corp Employee Handbook.pdf', '/docs/acme/handbook_v3.pdf', 'PDF', 1);\n",
      "INSERT INTO onboarding_plans (plan_id, company_id, title, description, created_by_user_id, is_active) VALUES (1, 1, 'Standard Engineering Onboarding', 'The standard onboarding plan for all new software engineers.', 1, TRUE);\n",
      "INSERT INTO tasks (task_id, plan_id, title, description, due_days_after_start, order_in_plan, document_id) VALUES (1, 1, 'Review Employee Handbook', 'Read and acknowledge the company policies outlined in the employee handbook.', 1, 1, 1);\n",
      "INSERT INTO tasks (task_id, plan_id, title, description, due_days_after_start, order_in_plan) VALUES (2, 1, 'Set up development environment', 'Follow the guide to install all necessary software and tools on your machine.', 3, 2);\n",
      "INSERT INTO tasks (task_id, plan_id, title, description, due_days_after_start, order_in_plan) VALUES (3, 1, 'First 1:1 with Manager', 'Schedule and complete your introductory one-on-one meeting with your manager.', 5, 3);\n",
      "INSERT INTO onboarding_processes (process_id, new_hire_user_id, plan_id, hiring_manager_user_id, start_date, status) VALUES (1, 3, 1, 2, '2024-05-15', 'In Progress');\n",
      "INSERT INTO assigned_tasks (assigned_task_id, process_id, task_id, status, due_date) VALUES (1, 1, 1, 'Pending', '2024-05-16');\n",
      "INSERT INTO assigned_tasks (assigned_task_id, process_id, task_id, status, due_date) VALUES (2, 1, 2, 'Pending', '2024-05-18');\n",
      "INSERT INTO assigned_tasks (assigned_task_id, process_id, task_id, status, due_date) VALUES (3, 1, 3, 'Pending', '2024-05-20');\n",
      "INSERT INTO notifications (notification_id, user_id, event_type, content, is_read, created_at) VALUES (1, 3, 'ONBOARDING_STARTED', 'Welcome to Acme Corp, Charlie! Your onboarding tasks have been assigned.', FALSE, '2024-05-15T09:05:00Z');\n",
      "INSERT INTO notifications (notification_id, user_id, event_type, content, is_read, created_at) VALUES (2, 3, 'TASK_DUE_SOON', 'Reminder: Your task \"Review Employee Handbook\" is due tomorrow.', FALSE, '2024-05-15T14:00:00Z');\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate realistic seed data.\n",
    "seed_data_prompt = f\"\"\"\n",
    "Using the following SQL schema and Product Requirements Document, generate realistic SQL INSERT statements to seed the database with sample data.\n",
    "SQL Schema:\n",
    "{cleaned_schema}\n",
    "Product Requirements Document (PRD):\n",
    "{prd_content}\n",
    "Author high-quality data that:\n",
    "- Populates every table that contains NOT NULL or foreign key constraints (roles, departments, teams, users, templates, template_tasks, onboarding_plans, onboarding_tasks, documents, task_documents, notifications, surveys, survey_questions, survey_assignments, survey_responses).\n",
    "- Uses only column names that exist in the schema and provides values for every required column.\n",
    "- Respects ENUM/CHECK constraints (e.g., status values, notification types, question_type options) and uses ISO-8601 timestamps or CURRENT_TIMESTAMP where appropriate.\n",
    "- Keeps identifiers consistent across inserts (e.g., onboarding_tasks.assignee_user_id must reference an existing users.user_id).\n",
    "Return 10-15 INSERT statements with no markdown code fences or commentary.\n",
    "\"\"\"\n",
    "enhanced_data_prompt = prompt_enhancer(seed_data_prompt)\n",
    "print(\"--- SQL Enhanced Seed Data Generation Prompt ---\")\n",
    "print (enhanced_data_prompt)\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(\n",
    "        enhanced_data_prompt,\n",
    "        client,\n",
    "        model_name,\n",
    "        api_provider,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql', overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Creating and Seeding a Live Database\n",
    "\n",
    "**Task:** This is a critical technical step. You will write a Python script to execute the generated SQL files, creating a live `onboarding.db` file that your application will use.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Complete the `create_database` function below.\n",
    "2.  The function should first connect to (and thus create) a SQLite database file named `artifacts/onboarding.db`.\n",
    "3.  It should then open and execute the `schema.sql` file to create the tables.\n",
    "4.  Finally, it should open and execute the `seed_data.sql` file to populate the tables.\n",
    "5.  Use a `try...finally` block to ensure the database connection is always closed, even if an error occurs.\n",
    "\n",
    "> **Hint:** The `try...finally` block is a crucial Python pattern. The code in the `finally` block will run whether the `try` block succeeds or fails, making it the perfect place to ensure resources like database connections are always closed.\n",
    "\n",
    "**Expected Quality:** A physical `onboarding.db` file in your `artifacts` folder. This is a tangible asset that proves your design is valid and provides a concrete foundation for backend development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to database at c:\\Workspace\\AG-AISOFTDEV\\artifacts\\onboarding.db\n",
      "Tables created successfully.\n",
      "Seed data inserted successfully.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # TODO: Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "        \n",
    "        # Read the content of the schema file using load_artifact.\n",
    "        schema_sql = load_artifact(os.path.relpath(schema_path, project_root))\n",
    "        if not schema_sql:\n",
    "            print(\"Error: Schema SQL is empty or missing.\")\n",
    "            return\n",
    "        \n",
    "        # Execute the schema SQL script.\n",
    "        cursor.executescript(schema_sql)\n",
    "        print(\"Tables created successfully.\")\n",
    "        \n",
    "        # Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(os.path.relpath(seed_path, project_root))\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted successfully.\")\n",
    "            else:\n",
    "                print(\"Warning: Seed SQL is empty. Skipping data load.\")\n",
    "        else:\n",
    "            print(\"Seed data file not found; skipping data load.\")\n",
    "        \n",
    "        # Commit the changes to the database.\n",
    "        conn.commit()\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        # Ensure the connection is closed if it was opened.\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"artifacts\", \"onboarding.db\")\n",
    "schema_file = os.path.join(project_root, \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now moved from abstract requirements to a concrete, physical database artifact. You've used an LLM to design a schema, generate realistic test data, and then used a Python script to bring that database to life. This `onboarding.db` file is the foundation upon which we will build our API in Day 3.\n",
    "\n",
    "> **Key Takeaway:** The ability to generate structured data definitions (like a SQL schema) from unstructured text (like a PRD) is a core skill in AI-assisted development. It automates a critical and often time-consuming design step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
