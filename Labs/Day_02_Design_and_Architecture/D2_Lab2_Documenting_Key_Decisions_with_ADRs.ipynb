{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:06:41,198 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "# [Title of ADR]\n",
      "\n",
      "## Status\n",
      "\n",
      "[Proposed | Accepted | Deprecated | Superseded]\n",
      "\n",
      "## Context\n",
      "\n",
      "*   **Problem:** Describe the problem or challenge that this decision addresses. What is the user story, business need, or technical debt being solved?\n",
      "*   **Driving Forces:** List the key factors influencing this decision. Examples include non-functional requirements (performance, security, scalability), team skills, strategic alignment, or product goals.\n",
      "    *   -\n",
      "*   **Constraints:** List any constraints or limitations that must be considered. Examples include budget, timeline, existing technology stack, legal/compliance requirements, or company policies.\n",
      "    *   -\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will [describe the chosen solution or approach in a clear, concise statement].\n",
      "\n",
      "**Rationale:** [Explain why this decision was made. Reference the context, compare it to alternatives considered, and justify the choice based on the driving forces and constraints.]\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*   **Positive Outcomes:**\n",
      "    *   - [List the expected benefits and positive impacts of this decision.]\n",
      "*   **Negative Trade-offs:**\n",
      "    *   - [List the known downsides, risks, or trade-offs. What are we giving up?]\n",
      "*   **Future Work:**\n",
      "    *   - [List any follow-up actions, new decisions that are now required, or work that needs to be done to implement or mitigate the consequences of this decision.]\n",
      "# [Title of ADR]\n",
      "\n",
      "## Status\n",
      "\n",
      "[Proposed | Accepted | Deprecated | Superseded]\n",
      "\n",
      "## Context\n",
      "\n",
      "*   **Problem:** Describe the problem or challenge that this decision addresses. What is the user story, business need, or technical debt being solved?\n",
      "*   **Driving Forces:** List the key factors influencing this decision. Examples include non-functional requirements (performance, security, scalability), team skills, strategic alignment, or product goals.\n",
      "    *   -\n",
      "*   **Constraints:** List any constraints or limitations that must be considered. Examples include budget, timeline, existing technology stack, legal/compliance requirements, or company policies.\n",
      "    *   -\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will [describe the chosen solution or approach in a clear, concise statement].\n",
      "\n",
      "**Rationale:** [Explain why this decision was made. Reference the context, compare it to alternatives considered, and justify the choice based on the driving forces and constraints.]\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*   **Positive Outcomes:**\n",
      "    *   - [List the expected benefits and positive impacts of this decision.]\n",
      "*   **Negative Trade-offs:**\n",
      "    *   - [List the known downsides, risks, or trade-offs. What are we giving up?]\n",
      "*   **Future Work:**\n",
      "    *   - [List any follow-up actions, new decisions that are now required, or work that needs to be done to implement or mitigate the consequences of this decision.]\n"
     ]
    }
   ],
   "source": [
    "# Write a prompt to generate a markdown ADR template.\n",
    "adr_template_prompt = \"\"\"You are a principal engineer creating a reusable Architectural Decision Record template for a cross-functional product team. Produce polished markdown with clear headings and bullet placeholders. Include the following sections in this order: Title, Status, Context (with bullet prompts for problem, driving forces, constraints), Decision (with rationale line), and Consequences (sub-bullets for positive outcomes, negative trade-offs, and future work). Output pure markdown only—no surrounding code fences, no commentary.\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(\n",
    "    adr_template_prompt,\n",
    "    client,\n",
    "    model_name,\n",
    "    api_provider,\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "Of course. Here is an evaluation of database options for OnboardPro's semantic search and analytics needs, presented in the requested format.\n",
      "\n",
      "***\n",
      "\n",
      "**To:** Engineering Leadership\n",
      "**From:** Staff Research Assistant\n",
      "**Date:** October 26, 2023\n",
      "**Subject:** Evaluation of Database Options for Semantic Search and Analytics\n",
      "\n",
      "This document provides an unbiased comparison between using PostgreSQL with the pgvector extension and adopting a specialized vector database to meet OnboardPro's product requirements.\n",
      "\n",
      "### 1. Summary of Workload Requirements\n",
      "\n",
      "The OnboardPro platform requires a database solution to support two primary functions: semantic search and user analytics. The specific characteristics of our workload are:\n",
      "\n",
      "*   **Semantic Search:** The core feature is enabling new hires to ask natural language questions and find relevant information within a corpus of company policies, onboarding guides, and knowledge base articles. This requires storing vector embeddings alongside the source text.\n",
      "*   **Rich, Filtered Queries:** Searches must be contextual. A query for \"PTO policy\" should be filterable by the employee's department, location, or hire date. This means the vector search must operate on a subset of data defined by structured, relational metadata.\n",
      "*   **Analytics and Dashboarding:** The platform will provide dashboards to HR administrators, showing metrics like the most frequently asked questions, search success rates per department, or onboarding document engagement over time. This requires performing aggregate queries across both the structured HR data and the search activity data.\n",
      "*   **Data Security and Compliance:** The system handles sensitive, personally identifiable information (PII) and confidential HR documents. The chosen solution must have a mature security model, support strong access controls, and facilitate compliance with standards like SOC 2 and GDPR.\n",
      "*   **Moderate and Growing Scale:** Initially, we project managing vectors for tens of thousands to low millions of documents. The solution must handle this scale efficiently while offering a clear path for future growth.\n",
      "*   **Operational Simplicity:** As a growing SaaS, minimizing operational complexity and cognitive overhead for the engineering team is a high priority.\n",
      "\n",
      "### 2. PostgreSQL with pgvector Extension\n",
      "\n",
      "This approach involves using our existing or a new PostgreSQL instance and enabling vector search capabilities via the open-source `pgvector` extension.\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "*   **Unified Data Architecture:** Vector embeddings reside in the same database, and often the same table, as the source text and its associated metadata (e.g., `document_id`, `department`, `access_level`). This dramatically simplifies filtered queries, as a single SQL query can perform both metadata filtering and vector similarity search.\n",
      "*   **Simplified Operations:** The team can leverage existing PostgreSQL expertise for management, backups, replication, and monitoring. There is only one database system to secure, maintain, and scale, reducing overall operational burden.\n",
      "*   **Powerful Analytics:** The full power of SQL is available for complex analytics and dashboarding. Joining search query logs with employee data and document metadata to generate insights is straightforward and efficient.\n",
      "*   **Mature Security Model:** We can utilize PostgreSQL's robust and battle-tested security features, including row-level security (RLS), granular permissions, and encryption. Proving compliance is simpler with a single, well-understood data store.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "*   **Potential for Resource Contention:** The database server must handle both traditional transactional (OLTP) queries and resource-intensive Approximate Nearest Neighbor (ANN) search queries. A spike in one workload could potentially impact the performance of the other without careful resource management and tuning.\n",
      "*   **Performance at Extreme Scale:** While performant for millions of vectors, it may not match the raw query speed of a specialized, memory-first database at a scale of hundreds of millions or billions of vectors.\n",
      "*   **Tuning Complexity:** Achieving optimal performance requires tuning both standard PostgreSQL parameters and `pgvector` index parameters (e.g., `ivfflat` lists or `hnsw` M and ef_construction), which adds a layer of specific knowledge required.\n",
      "\n",
      "**Operational Risks:**\n",
      "\n",
      "*   **Monolithic Scaling:** The entire database must be scaled (CPU, RAM, Disk) even if only the vector search component is the bottleneck. This can be less cost-efficient than scaling components independently.\n",
      "*   **Extension Dependency:** The functionality is dependent on the `pgvector` extension's development and compatibility with future PostgreSQL versions. This is a common and generally low-risk model but remains a dependency.\n",
      "\n",
      "### 3. Specialized Vector Database (e.g., ChromaDB, FAISS-backed service)\n",
      "\n",
      "This approach involves introducing a second, purpose-built database dedicated solely to storing, indexing, and querying vector embeddings.\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "*   **Optimized Search Performance:** These systems are engineered exclusively for high-speed, low-latency ANN search. They often employ more advanced indexing or memory management techniques to deliver the best possible performance, especially at very large scales.\n",
      "*   **Independent Scalability:** The vector search workload can be scaled independently of the primary application database. If semantic search usage explodes, we can add resources to the vector database cluster without touching the PostgreSQL instance that handles user accounts and other relational data.\n",
      "*   **Simplified Vector API:** The developer interface is focused purely on vector operations (e.g., `upsert`, `query`), which can be straightforward for ML-focused tasks.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "*   **Increased Architectural Complexity:** This introduces a second stateful system into our infrastructure. We must now manage, monitor, and back up two different databases.\n",
      "*   **Data Synchronization Challenges:** Metadata required for filtering (like department or location) must be duplicated from PostgreSQL into the vector database. This creates a data consistency challenge; if an employee's record is updated in PostgreSQL, a mechanism must ensure the change is propagated to the vector database to prevent incorrect search results.\n",
      "*   **Complex Query Logic:** Performing a filtered search requires a multi-step process: either querying the vector database using its metadata filters (which are often less powerful than SQL) or fetching vector IDs from the vector database and then running a `WHERE id IN (...)` query against PostgreSQL. This is more complex to implement and can be less performant than a single-database query.\n",
      "*   **Divided Security and Compliance:** We must secure and audit two separate systems that both store sensitive data or metadata. This doubles the surface area for security vulnerabilities and complicates compliance efforts.\n",
      "\n",
      "**Operational Risks:**\n",
      "\n",
      "*   **Data Consistency Failures:** The synchronization logic between the primary and vector databases is a critical point of failure. A bug or outage could lead to stale or incorrect data, directly impacting search result quality and correctness.\n",
      "*   **System Integration Overhead:** The application becomes a distributed system by default, introducing network latency and another potential point of failure between the application, PostgreSQL, and the vector database.\n",
      "*   **Ecosystem Immaturity:** The specialized vector database market is newer and more fragmented. Some solutions may lack the stability, long-term support, and robust tooling of a mature system like PostgreSQL.\n",
      "\n",
      "### 4. Recommendation Criteria\n",
      "\n",
      "The choice between these two architectures is a trade-off between unified simplicity and specialized performance. The following criteria can guide the decision for OnboardPro:\n",
      "\n",
      "**Choose PostgreSQL + pgvector if:**\n",
      "\n",
      "*   **Rich metadata filtering is a core product requirement.** Our need to filter searches by HR data makes this the most significant factor.\n",
      "*   **Operational simplicity and minimizing new infrastructure are high priorities.**\n",
      "*   **The ability to run complex analytical queries joining user, document, and search data is crucial for our dashboarding features.**\n",
      "*   **A single, unified security and compliance model is preferred for handling sensitive HR data.**\n",
      "*   The projected scale for the next 1-2 years is under 50 million vectors.\n",
      "\n",
      "**Choose a Specialized Vector Database if:**\n",
      "\n",
      "*   The primary requirement becomes near-instantaneous search latency at a massive scale (hundreds of millions of vectors or more).\n",
      "*   Vector search is the dominant workload, and metadata filtering is minimal or not required.\n",
      "*   The vector search service needs to be scaled completely independently from the rest of the application stack.\n",
      "*   The engineering organization has the capacity and expertise to manage the operational complexity of a distributed data architecture and solve data synchronization challenges.\n",
      "Of course. Here is an evaluation of database options for OnboardPro's semantic search and analytics needs, presented in the requested format.\n",
      "\n",
      "***\n",
      "\n",
      "**To:** Engineering Leadership\n",
      "**From:** Staff Research Assistant\n",
      "**Date:** October 26, 2023\n",
      "**Subject:** Evaluation of Database Options for Semantic Search and Analytics\n",
      "\n",
      "This document provides an unbiased comparison between using PostgreSQL with the pgvector extension and adopting a specialized vector database to meet OnboardPro's product requirements.\n",
      "\n",
      "### 1. Summary of Workload Requirements\n",
      "\n",
      "The OnboardPro platform requires a database solution to support two primary functions: semantic search and user analytics. The specific characteristics of our workload are:\n",
      "\n",
      "*   **Semantic Search:** The core feature is enabling new hires to ask natural language questions and find relevant information within a corpus of company policies, onboarding guides, and knowledge base articles. This requires storing vector embeddings alongside the source text.\n",
      "*   **Rich, Filtered Queries:** Searches must be contextual. A query for \"PTO policy\" should be filterable by the employee's department, location, or hire date. This means the vector search must operate on a subset of data defined by structured, relational metadata.\n",
      "*   **Analytics and Dashboarding:** The platform will provide dashboards to HR administrators, showing metrics like the most frequently asked questions, search success rates per department, or onboarding document engagement over time. This requires performing aggregate queries across both the structured HR data and the search activity data.\n",
      "*   **Data Security and Compliance:** The system handles sensitive, personally identifiable information (PII) and confidential HR documents. The chosen solution must have a mature security model, support strong access controls, and facilitate compliance with standards like SOC 2 and GDPR.\n",
      "*   **Moderate and Growing Scale:** Initially, we project managing vectors for tens of thousands to low millions of documents. The solution must handle this scale efficiently while offering a clear path for future growth.\n",
      "*   **Operational Simplicity:** As a growing SaaS, minimizing operational complexity and cognitive overhead for the engineering team is a high priority.\n",
      "\n",
      "### 2. PostgreSQL with pgvector Extension\n",
      "\n",
      "This approach involves using our existing or a new PostgreSQL instance and enabling vector search capabilities via the open-source `pgvector` extension.\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "*   **Unified Data Architecture:** Vector embeddings reside in the same database, and often the same table, as the source text and its associated metadata (e.g., `document_id`, `department`, `access_level`). This dramatically simplifies filtered queries, as a single SQL query can perform both metadata filtering and vector similarity search.\n",
      "*   **Simplified Operations:** The team can leverage existing PostgreSQL expertise for management, backups, replication, and monitoring. There is only one database system to secure, maintain, and scale, reducing overall operational burden.\n",
      "*   **Powerful Analytics:** The full power of SQL is available for complex analytics and dashboarding. Joining search query logs with employee data and document metadata to generate insights is straightforward and efficient.\n",
      "*   **Mature Security Model:** We can utilize PostgreSQL's robust and battle-tested security features, including row-level security (RLS), granular permissions, and encryption. Proving compliance is simpler with a single, well-understood data store.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "*   **Potential for Resource Contention:** The database server must handle both traditional transactional (OLTP) queries and resource-intensive Approximate Nearest Neighbor (ANN) search queries. A spike in one workload could potentially impact the performance of the other without careful resource management and tuning.\n",
      "*   **Performance at Extreme Scale:** While performant for millions of vectors, it may not match the raw query speed of a specialized, memory-first database at a scale of hundreds of millions or billions of vectors.\n",
      "*   **Tuning Complexity:** Achieving optimal performance requires tuning both standard PostgreSQL parameters and `pgvector` index parameters (e.g., `ivfflat` lists or `hnsw` M and ef_construction), which adds a layer of specific knowledge required.\n",
      "\n",
      "**Operational Risks:**\n",
      "\n",
      "*   **Monolithic Scaling:** The entire database must be scaled (CPU, RAM, Disk) even if only the vector search component is the bottleneck. This can be less cost-efficient than scaling components independently.\n",
      "*   **Extension Dependency:** The functionality is dependent on the `pgvector` extension's development and compatibility with future PostgreSQL versions. This is a common and generally low-risk model but remains a dependency.\n",
      "\n",
      "### 3. Specialized Vector Database (e.g., ChromaDB, FAISS-backed service)\n",
      "\n",
      "This approach involves introducing a second, purpose-built database dedicated solely to storing, indexing, and querying vector embeddings.\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "*   **Optimized Search Performance:** These systems are engineered exclusively for high-speed, low-latency ANN search. They often employ more advanced indexing or memory management techniques to deliver the best possible performance, especially at very large scales.\n",
      "*   **Independent Scalability:** The vector search workload can be scaled independently of the primary application database. If semantic search usage explodes, we can add resources to the vector database cluster without touching the PostgreSQL instance that handles user accounts and other relational data.\n",
      "*   **Simplified Vector API:** The developer interface is focused purely on vector operations (e.g., `upsert`, `query`), which can be straightforward for ML-focused tasks.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "*   **Increased Architectural Complexity:** This introduces a second stateful system into our infrastructure. We must now manage, monitor, and back up two different databases.\n",
      "*   **Data Synchronization Challenges:** Metadata required for filtering (like department or location) must be duplicated from PostgreSQL into the vector database. This creates a data consistency challenge; if an employee's record is updated in PostgreSQL, a mechanism must ensure the change is propagated to the vector database to prevent incorrect search results.\n",
      "*   **Complex Query Logic:** Performing a filtered search requires a multi-step process: either querying the vector database using its metadata filters (which are often less powerful than SQL) or fetching vector IDs from the vector database and then running a `WHERE id IN (...)` query against PostgreSQL. This is more complex to implement and can be less performant than a single-database query.\n",
      "*   **Divided Security and Compliance:** We must secure and audit two separate systems that both store sensitive data or metadata. This doubles the surface area for security vulnerabilities and complicates compliance efforts.\n",
      "\n",
      "**Operational Risks:**\n",
      "\n",
      "*   **Data Consistency Failures:** The synchronization logic between the primary and vector databases is a critical point of failure. A bug or outage could lead to stale or incorrect data, directly impacting search result quality and correctness.\n",
      "*   **System Integration Overhead:** The application becomes a distributed system by default, introducing network latency and another potential point of failure between the application, PostgreSQL, and the vector database.\n",
      "*   **Ecosystem Immaturity:** The specialized vector database market is newer and more fragmented. Some solutions may lack the stability, long-term support, and robust tooling of a mature system like PostgreSQL.\n",
      "\n",
      "### 4. Recommendation Criteria\n",
      "\n",
      "The choice between these two architectures is a trade-off between unified simplicity and specialized performance. The following criteria can guide the decision for OnboardPro:\n",
      "\n",
      "**Choose PostgreSQL + pgvector if:**\n",
      "\n",
      "*   **Rich metadata filtering is a core product requirement.** Our need to filter searches by HR data makes this the most significant factor.\n",
      "*   **Operational simplicity and minimizing new infrastructure are high priorities.**\n",
      "*   **The ability to run complex analytical queries joining user, document, and search data is crucial for our dashboarding features.**\n",
      "*   **A single, unified security and compliance model is preferred for handling sensitive HR data.**\n",
      "*   The projected scale for the next 1-2 years is under 50 million vectors.\n",
      "\n",
      "**Choose a Specialized Vector Database if:**\n",
      "\n",
      "*   The primary requirement becomes near-instantaneous search latency at a massive scale (hundreds of millions of vectors or more).\n",
      "*   Vector search is the dominant workload, and metadata filtering is minimal or not required.\n",
      "*   The vector search service needs to be scaled completely independently from the rest of the application stack.\n",
      "*   The engineering organization has the capacity and expertise to manage the operational complexity of a distributed data architecture and solve data synchronization challenges.\n"
     ]
    }
   ],
   "source": [
    "# Write a prompt to research database options.\n",
    "db_research_prompt = \"\"\"Act as an unbiased staff-level research assistant evaluating database options for OnboardPro’s semantic search and analytics needs. Compare using PostgreSQL with the pgvector extension versus adopting a specialized vector database such as ChromaDB or FAISS-backed service. Provide a structured markdown response with: (1) summary of the workload requirements (based on a new-hire onboarding SaaS handling secure HR data, moderate scale, need for analytics/dashboarding); (2) pros, cons, and operational risks for PostgreSQL + pgvector; (3) pros, cons, and operational risks for a specialized vector database; and (4) a balanced recommendation criteria list highlighting when each option is preferable. Avoid code fences and keep tone objective.\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(\n",
    "    db_research_prompt,\n",
    "    client,\n",
    "    model_name,\n",
    "    api_provider,\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "# ADR-001: Vector Store for Semantic Search and Analytics\n",
      "\n",
      "## Status\n",
      "\n",
      "Accepted\n",
      "\n",
      "## Context\n",
      "\n",
      "*   **Problem:** The OnboardPro platform requires a backend to support two core features: 1) A semantic search capability allowing users to ask natural language questions against a corpus of onboarding documents, and 2) Analytics dashboards for HR administrators to track search usage and effectiveness. This solution must store vector embeddings alongside structured metadata and support complex, filtered queries.\n",
      "*   **Driving Forces:** List the key factors influencing this decision.\n",
      "    *   - **Rich, Filtered Queries:** Search queries must be filterable by structured metadata (e.g., department, location, hire date) in a single, atomic operation.\n",
      "    *   - **Unified Analytics:** The system must support complex analytical queries that join search activity data with relational HR data for dashboarding.\n",
      "    *   - **Operational Simplicity:** Minimizing new infrastructure components and cognitive overhead for the engineering team is a high priority.\n",
      "    *   - **Security and Compliance:** The solution must handle sensitive PII and confidential documents with a mature, auditable security model (e.g., for SOC 2, GDPR).\n",
      "*   **Constraints:** List any constraints or limitations that must be considered.\n",
      "    *   - **Moderate Scale:** The initial workload is projected to be in the tens of thousands to low millions of vectors, with a clear path for future growth.\n",
      "    *   - **Existing Expertise:** The team has significant operational experience with PostgreSQL.\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will adopt PostgreSQL with the `pgvector` extension as the primary vector store for the OnboardPro platform. This single database instance will store vector embeddings, the source text, and all associated relational metadata.\n",
      "\n",
      "**Rationale:** This decision was made because a unified data architecture is the most effective way to meet our core product requirements. The research summary highlighted that our primary need is for rich, metadata-filtered vector searches. PostgreSQL with `pgvector` excels here, allowing us to perform metadata filtering and vector similarity search within a single, efficient SQL query. This dramatically simplifies application logic compared to the alternative of a specialized vector database, which would require complex, multi-step queries and introduce data synchronization challenges between two separate systems.\n",
      "\n",
      "Furthermore, this approach directly supports our operational goals. By leveraging our existing PostgreSQL infrastructure and expertise, we minimize operational complexity, cost, and the learning curve for the team. The full power of SQL is available for our analytics and dashboarding features, making it straightforward to generate insights by joining search logs with user and document data. Finally, using PostgreSQL's mature, battle-tested security model (including Row-Level Security) simplifies our compliance and data protection efforts for sensitive HR information. While a specialized database might offer higher performance at extreme scale, the operational simplicity and powerful querying capabilities of the PostgreSQL solution provide a superior trade-off for our current and projected needs.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*   **Positive Outcomes:**\n",
      "    *   - **Simplified Architecture:** A single data store for relational data and vectors reduces system complexity, making development, deployment, and maintenance easier.\n",
      "    *   - **Powerful, Efficient Queries:** The ability to combine metadata filters, full-text search, and vector search in one query simplifies application code and improves performance for our key use cases.\n",
      "    *   - **Reduced Operational Overhead:** We leverage existing team skills and tooling for backups, monitoring, security, and scaling, avoiding the need to manage a new type of database.\n",
      "*   **Negative Trade-offs:**\n",
      "    *   - **Potential Resource Contention:** Transactional (OLTP) and vector search (ANN) workloads will compete for the same database resources (CPU, RAM, I/O).\n",
      "    *   - **Scaling Limitations:** While sufficient for our projected needs, this solution may not match the raw query performance of a specialized vector database at a scale of hundreds of millions of vectors.\n",
      "    *   - **Extension Dependency:** Our vector search functionality is dependent on the open-source `pgvector` extension's continued development and compatibility with future PostgreSQL versions.\n",
      "*   **Future Work:**\n",
      "    *   - **Monitoring and Tuning:** Implement detailed monitoring on database performance to detect resource contention. Develop best practices for tuning `pgvector` indexes (`HNSW`, `IVFFlat`) and PostgreSQL configurations for our specific workload.\n",
      "    *   - **Workload Isolation Strategy:** Plan for the use of read replicas to offload analytical queries or vector searches if performance degradation is observed.\n",
      "    *   - **Periodic Re-evaluation:** Re-assess this decision if our data scale grows beyond 50 million vectors or if query latency becomes a critical product issue.\n",
      "# ADR-001: Vector Store for Semantic Search and Analytics\n",
      "\n",
      "## Status\n",
      "\n",
      "Accepted\n",
      "\n",
      "## Context\n",
      "\n",
      "*   **Problem:** The OnboardPro platform requires a backend to support two core features: 1) A semantic search capability allowing users to ask natural language questions against a corpus of onboarding documents, and 2) Analytics dashboards for HR administrators to track search usage and effectiveness. This solution must store vector embeddings alongside structured metadata and support complex, filtered queries.\n",
      "*   **Driving Forces:** List the key factors influencing this decision.\n",
      "    *   - **Rich, Filtered Queries:** Search queries must be filterable by structured metadata (e.g., department, location, hire date) in a single, atomic operation.\n",
      "    *   - **Unified Analytics:** The system must support complex analytical queries that join search activity data with relational HR data for dashboarding.\n",
      "    *   - **Operational Simplicity:** Minimizing new infrastructure components and cognitive overhead for the engineering team is a high priority.\n",
      "    *   - **Security and Compliance:** The solution must handle sensitive PII and confidential documents with a mature, auditable security model (e.g., for SOC 2, GDPR).\n",
      "*   **Constraints:** List any constraints or limitations that must be considered.\n",
      "    *   - **Moderate Scale:** The initial workload is projected to be in the tens of thousands to low millions of vectors, with a clear path for future growth.\n",
      "    *   - **Existing Expertise:** The team has significant operational experience with PostgreSQL.\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will adopt PostgreSQL with the `pgvector` extension as the primary vector store for the OnboardPro platform. This single database instance will store vector embeddings, the source text, and all associated relational metadata.\n",
      "\n",
      "**Rationale:** This decision was made because a unified data architecture is the most effective way to meet our core product requirements. The research summary highlighted that our primary need is for rich, metadata-filtered vector searches. PostgreSQL with `pgvector` excels here, allowing us to perform metadata filtering and vector similarity search within a single, efficient SQL query. This dramatically simplifies application logic compared to the alternative of a specialized vector database, which would require complex, multi-step queries and introduce data synchronization challenges between two separate systems.\n",
      "\n",
      "Furthermore, this approach directly supports our operational goals. By leveraging our existing PostgreSQL infrastructure and expertise, we minimize operational complexity, cost, and the learning curve for the team. The full power of SQL is available for our analytics and dashboarding features, making it straightforward to generate insights by joining search logs with user and document data. Finally, using PostgreSQL's mature, battle-tested security model (including Row-Level Security) simplifies our compliance and data protection efforts for sensitive HR information. While a specialized database might offer higher performance at extreme scale, the operational simplicity and powerful querying capabilities of the PostgreSQL solution provide a superior trade-off for our current and projected needs.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*   **Positive Outcomes:**\n",
      "    *   - **Simplified Architecture:** A single data store for relational data and vectors reduces system complexity, making development, deployment, and maintenance easier.\n",
      "    *   - **Powerful, Efficient Queries:** The ability to combine metadata filters, full-text search, and vector search in one query simplifies application code and improves performance for our key use cases.\n",
      "    *   - **Reduced Operational Overhead:** We leverage existing team skills and tooling for backups, monitoring, security, and scaling, avoiding the need to manage a new type of database.\n",
      "*   **Negative Trade-offs:**\n",
      "    *   - **Potential Resource Contention:** Transactional (OLTP) and vector search (ANN) workloads will compete for the same database resources (CPU, RAM, I/O).\n",
      "    *   - **Scaling Limitations:** While sufficient for our projected needs, this solution may not match the raw query performance of a specialized vector database at a scale of hundreds of millions of vectors.\n",
      "    *   - **Extension Dependency:** Our vector search functionality is dependent on the open-source `pgvector` extension's continued development and compatibility with future PostgreSQL versions.\n",
      "*   **Future Work:**\n",
      "    *   - **Monitoring and Tuning:** Implement detailed monitoring on database performance to detect resource contention. Develop best practices for tuning `pgvector` indexes (`HNSW`, `IVFFlat`) and PostgreSQL configurations for our specific workload.\n",
      "    *   - **Workload Isolation Strategy:** Plan for the use of read replicas to offload analytical queries or vector searches if performance degradation is observed.\n",
      "    *   - **Periodic Re-evaluation:** Re-assess this decision if our data scale grows beyond 50 million vectors or if query latency becomes a critical product issue.\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "# Write a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\"You are a staff engineer documenting an Architectural Decision Record for the OnboardPro onboarding platform. Populate the provided ADR template using the research summary while finalizing the decision to adopt PostgreSQL with the pgvector extension as the primary vector store. Requirements:\n",
    "- Set Status to Accepted and date the context to the current quarter generically (e.g., Q4 2025).\n",
    "- Reference key findings from the research when justifying the decision, noting trade-offs and mitigation strategies.\n",
    "- Keep tone concise and professional, suitable for version-controlled documentation.\n",
    "- Use only plain markdown and preserve the template structure without extra sections or commentary.\n",
    "\\n\\nADR TEMPLATE\\n--------------\\n{adr_template}\\n\\nRESEARCH SUMMARY\\n----------------\\n{db_research_output}\\n\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(\n",
    "        synthesis_prompt,\n",
    "        client,\n",
    "        model_name,\n",
    "        api_provider,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
